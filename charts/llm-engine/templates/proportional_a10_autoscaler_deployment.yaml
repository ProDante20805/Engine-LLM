{{- if not .Values.serviceIdentifier }}
{{- if .Values.autoscaling.prewarming.enabled }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-engine-proportional-a10-autoscaler-deployment
  labels:
    team: infra
    product: common-warm-nodes
spec:
  selector:
    matchLabels:
      app: llm-engine-proportional-a10-autoscaler-deployment
      version: v1
  template:
    metadata:
      labels:
        app: llm-engine-proportional-a10-autoscaler-deployment
        product: common-warm-nodes
        team: infra
        env: {{ .Values.context }}
        version: v1
      annotations:
        sidecar.istio.io/inject: "false"
    spec:
      tolerations:
        - key: "CriticalAddonsOnly"
          operator: "Exists"
      containers:
        - image: registry.k8s.io/cpa/cluster-proportional-autoscaler:1.8.5
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          name: main
          resources:
            requests:
                cpu: "20m"
                memory: "10Mi"
          command:
            - /cluster-proportional-autoscaler
            - --namespace={{ .Release.Namespace }}
            - --configmap=cluster-proportional-autoscaler
            - --target=deployment/llm-engine-balloon-a10
            - --default-params={"linear":{"nodesPerReplica":10,"preventSinglePointFailure":false,"includeUnschedulableNodes":false}}
            - --nodelabels=k8s.amazonaws.com/accelerator=nvidia-ampere-a10
            - --logtostderr=true
            - --v=2
      priorityClassName: system-cluster-critical
      serviceAccountName: {{ include "llmEngine.fullname" . }}
{{- end }}
{{- end }}
